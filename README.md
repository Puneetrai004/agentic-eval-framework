# Agentic Evaluation Framework ðŸš€

Evaluate AI agents across **instruction-following, hallucination detection, assumption control, and coherence** at scale.

## Features
- Batch scoring of 100s/1000s responses
- Rule-based + semantic scoring
- Explainability with reasons per score
- Leaderboard, heatmap, and trends visualization
- Optional **LLM-as-Judge** (flan-t5-small)

## Run on Hugging Face Spaces
1. Push this repo to GitHub
2. Create new Space â†’ choose **Streamlit**
3. Link GitHub repo
4. Done ðŸŽ‰
